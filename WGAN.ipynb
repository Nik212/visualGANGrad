{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "#import imlib as im\n",
    "import numpy as np\n",
    "#import pylib as py\n",
    "import tensorboardX\n",
    "import torch\n",
    "#import torchlib\n",
    "from torch import nn\n",
    "from tqdm.auto import trange, tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://raw.githubusercontent.com/anastasia-yaschenko/Generative-models/main/celeba%20(1).py'\n",
    "open('celeba.py', 'wb').write(requests.get(url).content);\n",
    "url = 'https://raw.githubusercontent.com/vpozdnyakov/DeepGenerativeModels/spring-2022/data/celeba/list_attr_celeba.txt'\n",
    "open('list_attr_celeba.txt', 'wb').write(requests.get(url).content);\n",
    "\n",
    "from celeba import CelebADataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 108\n",
    "\n",
    "offset_height = (218 - crop_size) // 2\n",
    "offset_width = (178 - crop_size) // 2\n",
    "crop = lambda x: x[:, offset_height:offset_height + crop_size, offset_width:offset_width + crop_size]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(crop),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CelebADataset(attr_file_path='list_attr_celeba.txt', transform=transform, crop=False)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "shape = (64, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **keyword_args):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def _get_norm_layer_2d(norm):\n",
    "    if norm == 'none':\n",
    "        return Identity\n",
    "    elif norm == 'batch_norm':\n",
    "        return nn.BatchNorm2d\n",
    "    elif norm == 'instance_norm':\n",
    "        return functools.partial(nn.InstanceNorm2d, affine=True)\n",
    "    elif norm == 'layer_norm':\n",
    "        return lambda num_features: nn.GroupNorm(1, num_features)\n",
    "    else:\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim=128,\n",
    "                 output_channels=3,\n",
    "                 dim=64,\n",
    "                 n_upsamplings=4,\n",
    "                 norm='batch_norm'):\n",
    "        super().__init__()\n",
    "\n",
    "        Norm = _get_norm_layer_2d(norm)\n",
    "\n",
    "        def dconv_norm_relu(in_dim, out_dim, kernel_size=4, stride=2, padding=1):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride=stride, padding=padding, bias=False or Norm == Identity),\n",
    "                Norm(out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # 1: 1x1 -> 4x4\n",
    "        d = min(dim * 2 ** (n_upsamplings - 1), dim * 8)\n",
    "        layers.append(dconv_norm_relu(input_dim, d, kernel_size=4, stride=1, padding=0))\n",
    "\n",
    "        # 2: upsamplings, 4x4 -> 8x8 -> 16x16 -> ...\n",
    "        for i in range(n_upsamplings - 1):\n",
    "            d_last = d\n",
    "            d = min(dim * 2 ** (n_upsamplings - 2 - i), dim * 8)\n",
    "            layers.append(dconv_norm_relu(d_last, d, kernel_size=4, stride=2, padding=1))\n",
    "\n",
    "        layers.append(nn.ConvTranspose2d(d, output_channels, kernel_size=4, stride=2, padding=1))\n",
    "        layers.append(nn.Tanh())\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.net(z)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_channels=3,\n",
    "                 dim=64,\n",
    "                 n_downsamplings=4,\n",
    "                 norm='batch_norm'):\n",
    "        super().__init__()\n",
    "\n",
    "        Norm = _get_norm_layer_2d(norm)\n",
    "\n",
    "        def conv_norm_lrelu(in_dim, out_dim, kernel_size=4, stride=2, padding=1):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_dim, out_dim, kernel_size, stride=stride, padding=padding, bias=False or Norm == Identity),\n",
    "                Norm(out_dim),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # 1: downsamplings, ... -> 16x16 -> 8x8 -> 4x4\n",
    "        d = dim\n",
    "        layers.append(nn.Conv2d(input_channels, d, kernel_size=4, stride=2, padding=1))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "\n",
    "        for i in range(n_downsamplings - 1):\n",
    "            d_last = d\n",
    "            d = min(dim * 2 ** (i + 1), dim * 8)\n",
    "            layers.append(conv_norm_lrelu(d_last, d, kernel_size=4, stride=2, padding=1))\n",
    "\n",
    "        # 2: logit\n",
    "        layers.append(nn.Conv2d(d, 1, kernel_size=4, stride=1, padding=0))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_G():\n",
    "    G.train()\n",
    "    D.train()\n",
    "\n",
    "    z = torch.randn(64, 128, 1, 1).to(device)\n",
    "    x_fake = G(z)\n",
    "\n",
    "    x_fake_d_logit = D(x_fake)\n",
    "    G_loss = -torch.mean(x_fake_d_logit)\n",
    "\n",
    "    G.zero_grad()\n",
    "    G_loss.backward()\n",
    "    G_optimizer.step()\n",
    "\n",
    "    return {'g_loss': G_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_line(real, fake):\n",
    "    shape = [real.size(0)] + [1] * (real.dim() - 1)\n",
    "    alpha = torch.rand(shape, device=real.device)\n",
    "    sample = real + alpha * (fake - real)\n",
    "    return sample\n",
    "\n",
    "\n",
    "def _sample_DRAGAN(real, fake):  # fake is useless\n",
    "    beta = torch.rand_like(real)\n",
    "    fake = real + 0.5 * real.std() * beta\n",
    "    sample = _sample_line(real, fake)\n",
    "    return sample\n",
    "    \n",
    "def _norm(x):\n",
    "    norm = x.view(x.size(0), -1).norm(p=2, dim=1)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def _one_mean_gp(grad):\n",
    "    norm = _norm(grad)\n",
    "    gp = ((norm - 1)**2).mean()\n",
    "    return gp\n",
    "\n",
    "\n",
    "def _zero_mean_gp(grad):\n",
    "    norm = _norm(grad)\n",
    "    gp = (norm**2).mean()\n",
    "    return gp\n",
    "\n",
    "\n",
    "def _lipschitz_penalty(grad):\n",
    "    norm = _norm(grad)\n",
    "    gp = (torch.max(torch.zeros_like(norm), norm - 1)**2).mean()\n",
    "    return gp\n",
    "\n",
    "def gradient_penalty(f, real, fake, gp_mode, sample_mode):\n",
    "    sample_fns = {\n",
    "        'line': _sample_line,\n",
    "        'real': lambda real, fake: real,\n",
    "        'fake': lambda real, fake: fake,\n",
    "        'dragan': _sample_DRAGAN,\n",
    "    }\n",
    "\n",
    "    gp_fns = {\n",
    "        '1-gp': _one_mean_gp,\n",
    "        '0-gp': _zero_mean_gp,\n",
    "        'lp': _lipschitz_penalty,\n",
    "    }\n",
    "\n",
    "    if gp_mode == 'none':\n",
    "        gp = torch.tensor(0, dtype=real.dtype, device=real.device)\n",
    "    else:\n",
    "        x = sample_fns[sample_mode](real, fake).detach()\n",
    "        x.requires_grad = True\n",
    "        pred = f(x)\n",
    "        grad = torch.autograd.grad(pred, x, grad_outputs=torch.ones_like(pred), create_graph=True)[0]\n",
    "        gp = gp_fns[gp_mode](grad)\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_D(x_real):\n",
    "    G.train()\n",
    "    D.train()\n",
    "\n",
    "    z = torch.randn(64, 128, 1, 1).to(device)\n",
    "    x_fake = G(z).detach()\n",
    "\n",
    "    x_real_d_logit = D(x_real)\n",
    "    x_fake_d_logit = D(x_fake)\n",
    "\n",
    "    x_real_d_loss, x_fake_d_loss = d_loss_fn(x_real_d_logit, x_fake_d_logit)\n",
    "    gp = gradient_penalty(functools.partial(D), x_real, x_fake, gp_mode='1-gp', sample_mode='line')\n",
    "\n",
    "    D_loss =  -torch.mean(x_real_d_logit) + torch.mean(x_fake_d_logit) + gp * 10.0\n",
    "\n",
    "    D.zero_grad()\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "\n",
    "    return {'d_loss': x_real_d_loss + x_fake_d_loss, 'gp': gp}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(z):\n",
    "    G.eval()\n",
    "    return G(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan_losses_fn():\n",
    "    bce = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def d_loss_fn(r_logit, f_logit):\n",
    "        r_loss = bce(r_logit, torch.ones_like(r_logit))\n",
    "        f_loss = bce(f_logit, torch.zeros_like(f_logit))\n",
    "        return r_loss, f_loss\n",
    "\n",
    "    def g_loss_fn(f_logit):\n",
    "        f_loss = bce(f_logit, torch.ones_like(f_logit))\n",
    "        return f_loss\n",
    "\n",
    "    return d_loss_fn, g_loss_fn\n",
    "\n",
    "\n",
    "def get_hinge_v1_losses_fn():\n",
    "    def d_loss_fn(r_logit, f_logit):\n",
    "        r_loss = torch.max(1 - r_logit, torch.zeros_like(r_logit)).mean()\n",
    "        f_loss = torch.max(1 + f_logit, torch.zeros_like(f_logit)).mean()\n",
    "        return r_loss, f_loss\n",
    "\n",
    "    def g_loss_fn(f_logit):\n",
    "        f_loss = torch.max(1 - f_logit, torch.zeros_like(f_logit)).mean()\n",
    "        return f_loss\n",
    "\n",
    "    return d_loss_fn, g_loss_fn\n",
    "\n",
    "\n",
    "def get_hinge_v2_losses_fn():\n",
    "    def d_loss_fn(r_logit, f_logit):\n",
    "        r_loss = torch.max(1 - r_logit, torch.zeros_like(r_logit)).mean()\n",
    "        f_loss = torch.max(1 + f_logit, torch.zeros_like(f_logit)).mean()\n",
    "        return r_loss, f_loss\n",
    "\n",
    "    def g_loss_fn(f_logit):\n",
    "        f_loss = -f_logit.mean()\n",
    "        return f_loss\n",
    "\n",
    "    return d_loss_fn, g_loss_fn\n",
    "\n",
    "\n",
    "def get_lsgan_losses_fn():\n",
    "    mse = torch.nn.MSELoss()\n",
    "\n",
    "    def d_loss_fn(r_logit, f_logit):\n",
    "        r_loss = mse(r_logit, torch.ones_like(r_logit))\n",
    "        f_loss = mse(f_logit, torch.zeros_like(f_logit))\n",
    "        return r_loss, f_loss\n",
    "\n",
    "    def g_loss_fn(f_logit):\n",
    "        f_loss = mse(f_logit, torch.ones_like(f_logit))\n",
    "        return f_loss\n",
    "\n",
    "    return d_loss_fn, g_loss_fn\n",
    "\n",
    "\n",
    "def get_wgan_losses_fn():\n",
    "    def d_loss_fn(r_logit, f_logit):\n",
    "        r_loss = -r_logit.mean()\n",
    "        f_loss = f_logit.mean()\n",
    "        return r_loss, f_loss\n",
    "\n",
    "    def g_loss_fn(f_logit):\n",
    "        f_loss = -f_logit.mean()\n",
    "        return f_loss\n",
    "\n",
    "    return d_loss_fn, g_loss_fn\n",
    "\n",
    "\n",
    "def get_adversarial_losses_fn(mode):\n",
    "    if mode == 'gan':\n",
    "        return get_gan_losses_fn()\n",
    "    elif mode == 'hinge_v1':\n",
    "        return get_hinge_v1_losses_fn()\n",
    "    elif mode == 'hinge_v2':\n",
    "        return get_hinge_v2_losses_fn()\n",
    "    elif mode == 'lsgan':\n",
    "        return get_lsgan_losses_fn()\n",
    "    elif mode == 'wgan':\n",
    "        return get_wgan_losses_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvGenerator(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(128, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (4): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Tanh()\n",
      "  )\n",
      ")\n",
      "ConvDiscriminator(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# networks\n",
    "n_G_upsamplings = n_D_downsamplings = 4\n",
    "lr = 0.0002\n",
    "\n",
    "G = ConvGenerator(128, shape[-1], n_upsamplings=n_G_upsamplings).to(device)\n",
    "D = ConvDiscriminator(shape[-1], n_downsamplings=n_D_downsamplings, norm='layer_norm').to(device)\n",
    "print(G)\n",
    "print(D)\n",
    "\n",
    "# adversarial_loss_functions\n",
    "d_loss_fn, g_loss_fn = get_adversarial_losses_fn('wgan')\n",
    "\n",
    "# optimizer\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as iio\n",
    "\n",
    "def _check(images, dtypes, min_value=-np.inf, max_value=np.inf):\n",
    "    # check type\n",
    "    assert isinstance(images, np.ndarray), '`images` should be np.ndarray!'\n",
    "\n",
    "    # check dtype\n",
    "    dtypes = dtypes if isinstance(dtypes, (list, tuple)) else [dtypes]\n",
    "    assert images.dtype in dtypes, 'dtype of `images` shoud be one of %s!' % dtypes\n",
    "\n",
    "    # check nan and inf\n",
    "    assert np.all(np.isfinite(images)), '`images` contains NaN or Inf!'\n",
    "\n",
    "    # check value\n",
    "    if min_value not in [None, -np.inf]:\n",
    "        l = '[' + str(min_value)\n",
    "    else:\n",
    "        l = '(-inf'\n",
    "        min_value = -np.inf\n",
    "    if max_value not in [None, np.inf]:\n",
    "        r = str(max_value) + ']'\n",
    "    else:\n",
    "        r = 'inf)'\n",
    "        max_value = np.inf\n",
    "    assert np.min(images) >= min_value and np.max(images) <= max_value, \\\n",
    "        '`images` should be in the range of %s!' % (l + ',' + r)\n",
    "\n",
    "\n",
    "def to_range(images, min_value=0.0, max_value=1.0, dtype=None):\n",
    "    \"\"\"Transform images from [-1.0, 1.0] to [min_value, max_value] of dtype.\"\"\"\n",
    "    _check(images, [np.float32, np.float64], -1.0, 1.0)\n",
    "    dtype = dtype if dtype else images.dtype\n",
    "    return ((images + 1.) / 2. * (max_value - min_value) + min_value).astype(dtype)\n",
    "\n",
    "def im2uint(images):\n",
    "    \"\"\"Transform images from [-1.0, 1.0] to uint8.\"\"\"\n",
    "    return to_range(images, 0, 255, np.uint8)\n",
    "\n",
    "def imwrite(image, path, quality=95, **plugin_args):\n",
    "    \"\"\"Save a [-1.0, 1.0] image.\"\"\"\n",
    "    iio.imsave(path, im2uint(image), quality=quality, **plugin_args)\n",
    "\n",
    "def immerge(images, n_rows=None, n_cols=None, padding=0, pad_value=0):\n",
    "    \"\"\"Merge images to an image with (n_rows * h) * (n_cols * w).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : numpy.array or object which can be converted to numpy.array\n",
    "        Images in shape of N * H * W(* C=1 or 3).\n",
    "\n",
    "    \"\"\"\n",
    "    images = np.array(images)\n",
    "    n = images.shape[0]\n",
    "    if n_rows:\n",
    "        n_rows = max(min(n_rows, n), 1)\n",
    "        n_cols = int(n - 0.5) // n_rows + 1\n",
    "    elif n_cols:\n",
    "        n_cols = max(min(n_cols, n), 1)\n",
    "        n_rows = int(n - 0.5) // n_cols + 1\n",
    "    else:\n",
    "        n_rows = int(n ** 0.5)\n",
    "        n_cols = int(n - 0.5) // n_rows + 1\n",
    "\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    shape = (h * n_rows + padding * (n_rows - 1),\n",
    "             w * n_cols + padding * (n_cols - 1))\n",
    "    if images.ndim == 4:\n",
    "        shape += (images.shape[3],)\n",
    "    img = np.full(shape, pad_value, dtype=images.dtype)\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % n_cols\n",
    "        j = idx // n_cols\n",
    "        img[j * (h + padding):j * (h + padding) + h,\n",
    "            i * (w + padding):i * (w + padding) + w, ...] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import shutil\n",
    "\n",
    "def save_checkpoint(obj, save_path, is_best=False, max_keep=None):\n",
    "    # save checkpoint\n",
    "    torch.save(obj, save_path)\n",
    "\n",
    "    # deal with max_keep\n",
    "    save_dir = os.path.dirname(save_path)\n",
    "    list_path = os.path.join(save_dir, 'checkpoint')\n",
    "\n",
    "    save_path = os.path.basename(save_path)\n",
    "    if os.path.exists(list_path):\n",
    "        with open(list_path) as f:\n",
    "            ckpt_list = f.readlines()\n",
    "            ckpt_list = [save_path + '\\n'] + ckpt_list\n",
    "    else:\n",
    "        ckpt_list = [save_path + '\\n']\n",
    "\n",
    "    if max_keep is not None:\n",
    "        for ckpt in ckpt_list[max_keep:]:\n",
    "            ckpt = os.path.join(save_dir, ckpt[:-1])\n",
    "            if os.path.exists(ckpt):\n",
    "                os.remove(ckpt)\n",
    "        ckpt_list[max_keep:] = []\n",
    "\n",
    "    with open(list_path, 'w') as f:\n",
    "        f.writelines(ckpt_list)\n",
    "    \n",
    "def load_checkpoint(ckpt_dir_or_file, map_location=None, load_best=False):\n",
    "    if os.path.isdir(ckpt_dir_or_file):\n",
    "        if load_best:\n",
    "            ckpt_path = os.path.join(ckpt_dir_or_file, 'best_model.ckpt')\n",
    "        else:\n",
    "            with open(os.path.join(ckpt_dir_or_file, 'checkpoint')) as f:\n",
    "                ckpt_path = os.path.join(ckpt_dir_or_file, f.readline()[:-1])\n",
    "    else:\n",
    "        ckpt_path = ckpt_dir_or_file\n",
    "    ckpt = torch.load(ckpt_path, map_location=map_location)\n",
    "    return ckpt   \n",
    "\n",
    "    # copy best\n",
    "    #if is_best:\n",
    "     #   shutil.copyfile(save_path, os.path.join(save_dir, 'best_model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "Epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3165/3165 [10:38<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3165/3165 [10:11<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3165/3165 [10:12<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3165/3165 [10:21<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3165/3165 [10:18<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3165/3165 [10:22<00:00,  5.08it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'output/wgan' #py.join('output', 'wgan')\n",
    "#py.mkdir(output_dir)\n",
    "\n",
    "# save settings\n",
    "#py.args_to_yaml(py.join(output_dir, 'settings.yml'), args)\n",
    "\n",
    "ckpt_dir1 = 'checkpoints/all_checkpoints' #py.join(output_dir, 'all_checkpoints')\n",
    "#py.mkdir(ckpt_dir1)\n",
    "# load checkpoint if exists\n",
    "ckpt_dir = 'checkpoints/checkpoints'#py.join(output_dir, 'checkpoints')\n",
    "#py.mkdir(ckpt_dir)\n",
    "\n",
    "\n",
    "try:\n",
    "    ckpt = load_checkpoint(ckpt_dir)\n",
    "    ep, it_d, it_g = ckpt['ep'], ckpt['it_d'], ckpt['it_g']\n",
    "    print(ep)\n",
    "    D.load_state_dict(ckpt['D'])\n",
    "    G.load_state_dict(ckpt['G'])\n",
    "    D_optimizer.load_state_dict(ckpt['D_optimizer'])\n",
    "    G_optimizer.load_state_dict(ckpt['G_optimizer'])\n",
    "except:\n",
    "    ep, it_d, it_g = 0, 0, 0\n",
    "\n",
    "# sample\n",
    "sample_dir = 'output/samples_training'#py.join(output_dir, 'samples_training')\n",
    "#py.mkdir(sample_dir)\n",
    "\n",
    "# main loop\n",
    "#writer = tensorboardX.SummaryWriter(py.join(output_dir, 'summaries'))\n",
    "z = torch.randn(100, 128, 1, 1).to(device)  # a fixed noise for sampling\n",
    "\n",
    "for ep_ in range(75, 81):\n",
    "    print('Epoch {}'.format(ep_))\n",
    "    if ep_ < ep:\n",
    "        continue\n",
    "    ep += 1\n",
    "\n",
    "    # train for an epoch\n",
    "    for x_real, _ in tqdm(data_loader):\n",
    "        x_real = x_real.to(device)\n",
    "        \n",
    "\n",
    "        D_loss_dict = train_D(x_real)\n",
    "        it_d += 1\n",
    "        #for k, v in D_loss_dict.items():\n",
    "            #writer.add_scalar('D/%s' % k, v.data.cpu().numpy(), global_step=it_d)\n",
    "\n",
    "        if it_d % 5 == 0:\n",
    "            G_loss_dict = train_G()\n",
    "            it_g += 1\n",
    "            #for k, v in G_loss_dict.items():\n",
    "                #writer.add_scalar('G/%s' % k, v.data.cpu().numpy(), global_step=it_g)\n",
    "\n",
    "        # sample\n",
    "        if it_g % 100 == 0:\n",
    "            x_fake = sample(z)\n",
    "            x_fake = np.transpose(x_fake.data.cpu().numpy(), (0, 2, 3, 1))\n",
    "            img = immerge(x_fake, n_rows=10).squeeze()\n",
    "            imwrite(img, os.path.join(sample_dir, 'iter-%09d.jpg' % it_g))\n",
    "\n",
    "    if ep % 5 == 0:\n",
    "        # save checkpoint\n",
    "        save_checkpoint({'ep': ep, 'it_d': it_d, 'it_g': it_g,\n",
    "                                'D': D.state_dict(),\n",
    "                                'G': G.state_dict(),\n",
    "                                'D_optimizer': D_optimizer.state_dict(),\n",
    "                                'G_optimizer': G_optimizer.state_dict()},\n",
    "                               os.path.join(ckpt_dir1, 'Epoch_(%d).ckpt' % ep)) #max_keep=1)\n",
    "    \n",
    "    # save checkpoint\n",
    "    save_checkpoint({'ep': ep, 'it_d': it_d, 'it_g': it_g,\n",
    "                            'D': D.state_dict(),\n",
    "                            'G': G.state_dict(),\n",
    "                            'D_optimizer': D_optimizer.state_dict(),\n",
    "                            'G_optimizer': G_optimizer.state_dict()},\n",
    "                            os.path.join(ckpt_dir, 'Epoch_(%d).ckpt' % ep), max_keep=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
